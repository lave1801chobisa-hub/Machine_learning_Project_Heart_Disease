# -*- coding: utf-8 -*-
"""Heart Disease Filming.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UM6HywGrmq3G3FAuXcZKMxyhtYkciKhO
"""



"""Important Parameter:
      Number of instances:302
      Number of attributes : 14    continous attributes
Each of the attributes:
    age: Age in years
    sex: Sex(1=male,0=female)
    cp: Chest pain type (Value 1 :typical angina ,Value 2: atypical angina,Value 3:non-aginal pain, Value 4 : asymptomatic)
    trestbps : Resting blood pressure(in mmHg on admission to the hospital)
    chol : Serum Cholestrol in mg/dl
    fbs : fast blood sugar > 120 mg/dl(1=true,0=false)
    restecg : Resting electrocardiographic result (0:normal , 1:having ST-T wave abnormality (T wave inversion and/or St elevation or depression of >0.05mV, 2 : showing probabal or definite left ventricular hypertrophy by Estes criteria
    thalach : Maximum heart rate achieved
    exang : Exercise include angina (1=yes,0=no)
    oldpeak : ST depression include by exercise relative to rest
    slope : the slope of the peak exercise ST segment (Value 1 : upsloping , Value 2: Flat , Value 3 : downsloping )
    ca : Number of major vessels
    thal : 3= normal ,6=fixed defect , 7= reversable defect
    HeartDisease: Diagnosis of heart disease - angiprahic disease status (Value 0:<50 % diameter narrowing , Value 1 : > 50% diameter narrowing ) in any major .
    Vessel : attributes 59 through 68 are vessels

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded = files.upload()

HDNames= ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','hal','HeartDisease']
Data =pd.read_excel('Ch3.ClevelandData.xlsx',names=HDNames)

print(Data.head(20))
print(Data.info())
summary = Data.describe()
print(summary)

DataNew= Data.replace('?',np.nan)
print(DataNew.info())

print(DataNew.isnull().sum())

"""

*   Replace the values with constant values
*   Set the values with other columns values



* Transform the data with functions
*  Delete row



"""

DataNew= DataNew.dropna()

DataNew.HeartDisease

print(DataNew.info())

"""# Standarization
x(Scaled)=(X-mean)/sd
 Mean=0 standard deviation =1


*   Mean=0 standard deviation =1
*   Value > mean will have +Z score


*    Value < mean will have -Z score





"""

InputNames = HDNames
InputNames.pop()

Input= pd.DataFrame(DataNew.iloc[:,0:13],columns=InputNames)
Input.shape

Target = pd.DataFrame(DataNew.iloc[:, 13],columns=['HeartDisease'])
Target.shape

from sklearn.preprocessing import StandardScaler

scaler= StandardScaler()
print(scaler.fit(Input))

InputScaled = scaler.fit_transform(Input)
InputScaled = pd.DataFrame(InputScaled,columns=InputNames)
summary = InputScaled.describe()
summary = summary.transpose()
print(summary)

boxplot=InputScaled.boxplot(column=InputNames,showmeans=True)
plt.show()

pd.plotting.scatter_matrix(InputScaled,figsize=(6,6))
plt.show()

CorData = InputScaled.corr(method='pearson')

with pd.option_context('display.max_rows', None, 'display.max_columns', CorData.shape[1]):
    print(CorData)

plt.matshow(CorData)
plt.xticks(range(len(CorData.columns)),CorData.columns)
plt.yticks(range(len(CorData.columns)),CorData.columns)
plt.colorbar()
plt.show()

print(InputScaled)

print(Target)

# split the data
from sklearn.model_selection import train_test_split
Input_train, Input_test, Target_train, Target_test = train_test_split(InputScaled, Target, test_size = 0.3, random_state = 5)
print(Input_train.shape)
print(Input_test.shape)
print(Target_train.shape)
print(Target_test.shape)

"""test_size = 0.3 means that 30 % of the data is divided up as data set.          
random_state parameter is used to set the seed used by the random number generator.                                                                      
InputScaled and Target parameters are inputs and target DataFrames.

Create a keras Sequential model


*   Import the Sequential class from keras.models
*   Stack the layers using the .add() method


*   Configure the learning process and using the .compile() method
*   Train the model on teh train dataset using the .fit() method
"""

from keras.models import Sequential
from keras.layers import Dense
model = Sequential()
model.add(Dense(30,input_dim=13,activation='tanh'))
model.add(Dense(20,activation='tanh'))
model.add(Dense(1,activation='sigmoid'))

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
model.fit(Input_train,Target_train,epochs=1000,verbose=1)

model.summary()

score=model.evaluate(Input_test,Target_test,verbose=0)
print('Keras Model Accuracy =',score[1])

Target_Classification=model.predict(Input_test)
Target_Classification = (Target_Classification > 0.5)|

from sklearn.metrics import confusion_matrix
print(confusion_matrix(Target_test,Target_Classification))

35+38

"""*   Input_train: Aarry of input training data
*   Target_train:Aarry of target (label)data


*   epochs = 1000: Number of epochs to train the model. An epoch is an iteration over the entire  x and y data provided
*   verbose = 1: An integer, either 0,1,or 2. Verbose mode: 0 =silent, 1= progress bar, 2= one line per epoch
"""